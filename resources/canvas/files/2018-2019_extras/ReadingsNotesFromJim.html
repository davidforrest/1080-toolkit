<h1>Notes on Perusall Readings #2 and #4 from Jim</h1>

<p>The following are notes from Jim on your most recent reading assignments questions. He addressed some of the questions on Reading Assignment (RA) #3 in class. &nbsp;We will be using this format when we don't have a chance to cover the confusion report from Perusall during our Friday meetings, however when possible we will bring these discussions to class.&nbsp;</p>
<p>Jim may add more notes over the weekend. New notes will be added to the top so you can easily see what's new.&nbsp;</p>
<p><span style="font-size: 18pt;"><strong>RA #2</strong></span></p>
<p><strong>Page 2</strong></p>
<p>Some confusion about what an envelope is.&nbsp; I like Loy's definition: the characteristic way that sound changes through time.&nbsp; But this is best explained by looking at some of the Audacity tracks, like the flute that we were listening to.&nbsp; When you look at the whole several-second-long track, you see the amplitude rise and fall over time.&nbsp; This is the envelope.&nbsp; As you zoom in, you can start to see the periodic wave shape.</p>
<p>As for wave shapes, they don't depend on amplitude, so sines at different amplitudes are all sine-shaped.&nbsp; And the mapping between what a wave looks like graphically (square, sawtooth) to what it sounds like can be pretty tricky.&nbsp; I can make two waves that look totally different and sound the same -- using partials with the same amplitudes and different phases.</p>
<p><strong>Page 3</strong></p>
<p><strong>Decibels</strong></p>
<p>To recap, a decibel is a relative measurement.&nbsp; Every 10 dB change is a 10-fold increase or decrease in power.&nbsp; But if your units are not watts, but rather units of pressure (Pascals) or volts, or digital full-scale, then it's a 20 dB change to make a 10X increase or decrease.&nbsp; That's why it's absolutely critical to know what the units are when somebody talks about dB, so you know whether to multiply by 2.&nbsp; Everyone, including sound professionals, makes this mistake.</p>
<p>Also, since decibels are a relative measure, it's important to know what the reference level is.&nbsp; For sound pressure (dBspl) the baseline 0dB is 20 micropascals.&nbsp; Power is usually expressed in dBm, where m stands for milliwatts.&nbsp; Audio electrical levels are often expressed in dBu, where 0 dB is the RMS voltage of a 1 mW sine wave across a 600-Ohm load.&nbsp; dBV is also common, where 0dB is 1Vrms.&nbsp; dBfs is decibels down from full scale in a digital system.</p>
<p>A VU meter sets its 0dB point at +4dBu, and adds a tricky factor: a mechanical time constant which smooths out impulsive noise.&nbsp; The time constant is relatively long -- hundreds of msec.</p>
<p>LUFS is a measure of perceived loudness, which is used in the broadcast industry mostly to keep advertisers from creating overly loud commercials.&nbsp; So now we're adding time constants _and_ frequency weighting to the metric.</p>
<p><strong>On Wave Propagation:</strong></p>
<p>Do air particles return to the place they started from at the end of the wave?</p>
<p>No.&nbsp; I blame this misconception on a lot of popular web simulations which show the air particles returning to where they started from, e.g.:</p>
<p>https://www.acs.psu.edu/drussell/demos/waves/wavemotion.html</p>
<p>Air molecules are whizzing around at 500 meters/second, faster than the speed of sound.&nbsp; Each molecule hits another molecule and changes direction 8 billion times a second.&nbsp; So when we're discussing air, we need to think statistically about local changes in the density of the air as sound waves pass through.</p>
<p><strong>Page 18</strong></p>
<p>Those interested in perfect pitch should google "absolute pitch", the preferred clinical term, especially along with "FMRI".&nbsp; Recent FMRI tests are showing some pretty odd stuff, esp the apparent mapping of tones into the area of the brain responsible for contextualizing vocabulary.&nbsp; Stay tuned -- more research has been done on absolute pitch in the past ten years than the previous hundred.</p>
<p><em><strong>It was mentioned in class that water makes two kinds of waves, longitudinal and transverse, but I don't understand how air doesn't also do this. It seems like as air particles get compressed in a sound wave, they would spread out vertically just like water. Is it because air can be compressed and water can't?</strong></em></p>
<p>Hooboy, what a complicated topic, and I'm still confused by it even after spending hours of research.&nbsp; Start by tossing a pebble into a pond and observing the ripples.&nbsp; Those ripples are waves, but they are not _acoustic_ waves.&nbsp; After all, they're only traveling at 20 MPH or so -- you can outrun them if you're fast.&nbsp; Like the waves in a Shive wave machine, water waves are a useful analogy for acoustic waves -- they reflect, refract, diffuse, etc. -- but they aren't acoustic waves.</p>
<p>That's not to say that sound doesn't travel in water -- it does, and faster than it does in air.&nbsp; Water waves are pressure waves, except (and now it gets even more confusing) transverse waves can develop at the surface, called Surface Acoustic Waves -- and these travel slower than the pressure waves, but far faster than the macroscopic water waves you get from dropping a pebble into a pond.&nbsp; Solids can have Surface Acoustic Waves as well -- they are commonly used in the electronics industry.&nbsp; In an earthquake, the surface waves (also called the "S" waves or "Secondary" waves or "Shake" waves) are the ones that do the damage.&nbsp; because they travel more slowly than the pressure (or "P" waves or "Primary" waves or "Push" waves) it is possible to create a warning system that detects P waves and shuts down critical systems before the "S" waves arrive.</p>
<p>So why doesn't air create transverse waves?&nbsp; Because it lacks the surface tension and other intermolecular forces of liquid water, so there's no restoring force.</p>
<p><em><strong>Then when two of the same instrument play the same note, shouldn't there be a chance that they will cancel each other out?</strong></em></p>
<p>We are about to get the perfect demonstration of that with the piano.&nbsp; Each note on a piano has two or three strings.&nbsp; The piano tuner deliberately tunes them very slightly out of tune from each other, which creates beats -- effectively the two notes canceling each other out.&nbsp; Typically these beats have very long periods -- on the order of seconds, and when you have three strings beating like that, the result is the gorgeous, complicated sound of a piano.</p>
<p><strong><em>Re: Measuring loudest sound without causing distortion on recording equipment &mdash; What recording method has the least distortion?</em></strong></p>
<p>Uncompressed digital, by a mile.&nbsp; 16-bit "CD-quality" audio has a dynamic range of 96 dB, which is better than all but the best tape machines, and modern digital audio can reach a dynamic range of more than 120 dB, which is limited mostly by microphones and amplifiers.</p>
<p>&nbsp;</p>
<p><span style="font-size: 14pt;"><strong>RA #4</strong></span></p>
<p><strong><em>How does the fact that people can have differently shaped ears then affect the way we hear. Has there been any correlation between ear shape and affinity to certain sounds been shown? Does this affect the way in-ear earphones are designed?</em></strong></p>
<p>Watch this video for now from Salma on what happens when sound waves bounce off of your ear lobes and how your brain is trained to resolve location based on that. Jim will have more to say about the above question soon.&nbsp;<a class="" href="https://youtu.be/Oai7HUqncAA?t=195%5D" data-ytt-failcnt="1">https://youtu.be/Oai7HUqncAA?t=195]</a></p>
<p><em><strong>Do additive synthesizers function off of this principle, or are individual oscillators able to output other waveforms without first constructing them from sinusoids?</strong></em></p>
<p>Purely additive synthesizers construct waveforms from sine waves.&nbsp; Practically all of them do the addition in the digital domain.&nbsp; The classic analog synthesizer (Moog, etc) is a "subtractive" synthesizer, which starts with a complex waveform like a sawtooth, then removes partials instead of adding them.&nbsp; There are also samplers, granular synthesizers, and various hybrids, which I will talk about when/if I discuss synths.</p>
<p>&nbsp;</p>
<p><em><strong>Is speech periodic at all? It doesn't seem like it would be to me. If it isn't, how does Fourier analysis work on it? Also, how are we able to recognize speech when there are so many different ways to sound out the same things (as people's voices have different timbres)?</strong></em></p>
<p>Vowel sounds are periodic, as you can see by recording your voice with Audacity and zooming in on a vowel sound.&nbsp; If Dr. Song doesn't do something like that on Monday, we can demonstrate it the following Friday.</p>
<p><em><strong>Is there really any difference between hearing a waveform constantly and hearing it for a short time? If so, is there any difference between an infinite and time-limited Fourier transform that should be meaningful to humans?</strong></em></p>
<p>That's a fun branch of psychoacoustics, and easy to test with tone bursts.&nbsp; Basically, bursts that last less than a few msec sound like clicks.&nbsp; As you increase the duration, they gradually start to sound tonal.&nbsp; The ear has the same time/frequency problem that a Fourier transform has.&nbsp; I think we showed a video or demo of this last year.</p>
